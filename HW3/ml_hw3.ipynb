{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 103590450 四資四 馬茂源"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-23T16:10:42.940831Z",
     "start_time": "2018-04-23T16:10:42.632012Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import FastICA\n",
    "from scipy.stats import multivariate_normal, norm\n",
    "import numpy as np\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-23T16:10:42.963893Z",
     "start_time": "2018-04-23T16:10:42.941834Z"
    }
   },
   "outputs": [],
   "source": [
    "class MyKNeighborsClassifier:\n",
    "    \n",
    "    def __init__(self, n_neighbors=3, **kwargs):\n",
    "        self._k = n_neighbors\n",
    "        self._X = self._y = None\n",
    "        self.set_params(**kwargs)\n",
    "            \n",
    "    def get_params(self, deep=True):\n",
    "        # suppose this estimator has parameters \"alpha\" and \"recursive\"\n",
    "        return self.__dict__\n",
    "\n",
    "    def set_params(self, **parameters):\n",
    "        for parameter, value in parameters.items():\n",
    "            setattr(self, parameter, value)\n",
    "        return self\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        self._X = X.copy()\n",
    "        self._y = y.copy()\n",
    "    \n",
    "    def _predict(self, x):\n",
    "        distances = np.apply_along_axis(lambda x1: np.linalg.norm(x-x1), \n",
    "                                        1, self._X)\n",
    "        X_candidates = np.argsort(distances)[:self._k]\n",
    "        y_candidates = self._y[X_candidates]\n",
    "        return np.argmax(np.bincount(y_candidates.astype('int64')))\n",
    "    \n",
    "    def score(self, X, y_true):\n",
    "        return accuracy_score(y_true, self.predict(X))\n",
    "    \n",
    "    def predict(self, X):\n",
    "        return np.apply_along_axis(lambda x: self._predict(x), 1, X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-23T16:10:42.974922Z",
     "start_time": "2018-04-23T16:10:42.964895Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150, 4) (150,)\n"
     ]
    }
   ],
   "source": [
    "iris = load_iris()\n",
    "feature_names = iris.feature_names.copy()\n",
    "iris_X = iris.data\n",
    "iris_y = iris.target\n",
    "print(iris_X.shape, iris_y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 . In  this  problem,  you  are  asked  to  use  ICA  on  Iris  dataset  for  dimensionality reduction  before classification.  To  simplify  the  problem,  you  do  not  need  to implement the ICA program. \n",
    "\n",
    "Instead, find an existing one and learn how to use it. As you may not be able to store internal parameters of the ICA, input all of the 150  samples  to  find  the  corresponding  independent  components  as  the preprocessing  step.  \n",
    "\n",
    "You  may assume  that  there  are  four  sources  and  four observations. On the obtained four components, pick the two components with largest energy as new features. Randomly pick 70 % of the samples (represented by  new features)  as  training  set  and  the  rest  as  test  set.  Implement  the  3-NN classifier  to  compute  the  accuracy. Repeat  the  drawing  and  the  3-NN classification 10 times and compute the average accuracy and accuracy variance. For simplicity, use the Euclidean distance in the k-NN computation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-23T16:10:42.980937Z",
     "start_time": "2018-04-23T16:10:42.975925Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ica = FastICA(n_components=2)\n",
    "ica_X = ica.fit_transform(iris_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-23T16:10:43.242633Z",
     "start_time": "2018-04-23T16:10:42.981941Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python36\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2026: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg acc:0.9466666666666667, variance of acc:0.0011061728395061721\n"
     ]
    }
   ],
   "source": [
    "acc = []\n",
    "for i in range(10):\n",
    "    train_X, test_X, train_y, test_y = train_test_split(ica_X, \n",
    "                                                        iris_y, \n",
    "                                                        train_size=0.7)\n",
    "    model = MyKNeighborsClassifier()\n",
    "    model.fit(train_X, train_y)\n",
    "    acc.append(model.score(test_X, test_y))\n",
    "print('avg acc:{}, variance of acc:{}'.format(np.mean(acc), np.var(acc)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 . We learned the k-means for clustering in the lecture. Implement the algorithm with the Iris dataset.\n",
    "\n",
    "In this problem, we know k = 3. Use the first sample in each class as the initial cluster center to do the clustering. \n",
    "\n",
    "Remember that the cluster centers are points in 4-dimensional space. To have a unique answer, use the same sequence given in the dataset to feed into your program. \n",
    "\n",
    "That is, do not shuffler the dataset. Once your program converges,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-23T16:10:43.275721Z",
     "start_time": "2018-04-23T16:10:43.242633Z"
    }
   },
   "outputs": [],
   "source": [
    "class MyKmeans:\n",
    "    \n",
    "    def __init__(self, n_clusters=3, init=None, max_iter=300, tol=1e-4):\n",
    "        self.n_clusters = n_clusters\n",
    "        self.centroids = init.copy()\n",
    "        self.max_iter = max_iter\n",
    "        self.tol = tol\n",
    "        \n",
    "    def _update_centroids(self, X, y):\n",
    "        for i, c in enumerate(np.unique(y)):\n",
    "            new_center = np.mean(X[y==c, :], axis=0)\n",
    "            self.centroids[i] = new_center\n",
    "            \n",
    "    def _predict(self, x):\n",
    "        return np.argmin(np.linalg.norm(self.centroids-x, axis=1))\n",
    "    \n",
    "    def predict(self, X):\n",
    "        return np.apply_along_axis(lambda x: self._predict(x), 1, X)\n",
    "    \n",
    "    def fit(self, X):\n",
    "        if self.centroids == 'random' or self.centroids is None:\n",
    "            idx = np.random.randint(X.shape[0], size=self.n_clusters)\n",
    "            self.centroids = X[idx, :]\n",
    "            # print(self.centroids)\n",
    "          \n",
    "        for i in range(self.max_iter):\n",
    "            y = self.predict(X)\n",
    "            previous_centroids = self.centroids.copy()\n",
    "            self._update_centroids(X, y)\n",
    "            \n",
    "            if np.all(np.linalg.norm(previous_centroids-self.centroids, \n",
    "                                     axis=1) \n",
    "                      < self.tol):\n",
    "                \n",
    "                print('convergence at iteration-{}'.format(i))\n",
    "                break\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-23T16:10:43.287753Z",
     "start_time": "2018-04-23T16:10:43.276725Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.1, 3.5, 1.4, 0.2],\n",
       "       [7. , 3.2, 4.7, 1.4],\n",
       "       [6.3, 3.3, 6. , 2.5]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "init = iris_X[[0, 50, 100], :]\n",
    "init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-23T16:10:43.300788Z",
     "start_time": "2018-04-23T16:10:43.288756Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence at iteration-3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python36\\lib\\site-packages\\ipykernel_launcher.py:21: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n"
     ]
    }
   ],
   "source": [
    "model = MyKmeans(init=init).fit(iris_X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (a) print out the coordinates of the cluster centers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-23T16:10:43.306804Z",
     "start_time": "2018-04-23T16:10:43.301791Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.006     , 3.418     , 1.464     , 0.244     ],\n",
       "       [5.9016129 , 2.7483871 , 4.39354839, 1.43387097],\n",
       "       [6.85      , 3.07368421, 5.74210526, 2.07105263]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.centroids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (b) The number of members (sample points) in each cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-23T16:10:43.314825Z",
     "start_time": "2018-04-23T16:10:43.307807Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([50, 62, 38], dtype=int64)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.bincount(model.predict(iris_X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (c) According to the labels of data samples, how many of them are placed in wrong clusters? Use a majority vote to determine the label of each cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-23T16:10:43.321844Z",
     "start_time": "2018-04-23T16:10:43.315828Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 16 samples are placed in wrong clusters.\n"
     ]
    }
   ],
   "source": [
    "error = iris_y - model.predict(iris_X)\n",
    "print('There are %d samples are placed in wrong clusters.'%(error[error != 0].shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-23T16:10:43.329867Z",
     "start_time": "2018-04-23T16:10:43.322847Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8933333333333333"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(iris_y, model.predict(iris_X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 . We know that the GMM can be viewed as a “soft” clustering method. To simplify the difficulty level, we will implement the univariate GMM. Use the third feature (petal length) as the input to your GMM. \n",
    "\n",
    "The settings are three Gaussians with the following initial values: $\\mu_{1}$= 1, $\\mu_{2}$= 4, $\\mu_{3}$= 6, $\\sigma_{1}^{2}$= $\\sigma_{2}^{2}$= $\\sigma_{3}^{2}$= 1, $a_{1}$= 0.5, $a_{2}$= $a_{3}$= 0.25. \n",
    "\n",
    "To have a unique answer, iterate the EM steps 3,000 times (epochs). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-23T16:10:43.336884Z",
     "start_time": "2018-04-23T16:10:43.330869Z"
    }
   },
   "outputs": [],
   "source": [
    "u = [1, 4, 6]\n",
    "stddev = [1, 1, 1]\n",
    "size = [0.5, 0.25, 0.25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-23T16:10:43.399049Z",
     "start_time": "2018-04-23T16:10:43.337888Z"
    }
   },
   "outputs": [],
   "source": [
    "class MyGMM:\n",
    "    \n",
    "    def __init__(self, mean, stddev, size, epoch=3000):\n",
    "        self.u = np.array(mean)\n",
    "        self.cov = np.array(stddev)**2\n",
    "        self.size = np.array(size)\n",
    "        self.epoch = epoch\n",
    "    \n",
    "\n",
    "    def _E_step(self, X):\n",
    "        '''\n",
    "        get r_ic\n",
    "        '''\n",
    "        R = norm.pdf(X, self.u, self.cov)\n",
    "        R = R*self.size\n",
    "        R /=  (np.sum(R, axis=1).reshape(-1,1))\n",
    "        return R\n",
    "    \n",
    "    def _M_step(self, R, X):\n",
    "        Mc = np.sum(R, axis=0)\n",
    "        new_size = Mc/R.shape[0]\n",
    "        new_mean = np.array([np.sum(rc*X.reshape(-1))/mc for rc, mc in zip(R.T, Mc)])\n",
    "        new_cov  = np.array([np.cov(rc*X.reshape(-1))    for rc, mc in zip(R.T, Mc)])\n",
    "        return new_mean, new_cov, new_size\n",
    "    \n",
    "    def _update(self, old, new):\n",
    "        if any(np.isnan(new)):\n",
    "            return (old, True)\n",
    "        \n",
    "        return (old, True) if all(np.isclose(old, new)) else (new, False)\n",
    "    \n",
    "    def fit(self, X):\n",
    "        for i in range(self.epoch):\n",
    "            \n",
    "            R = self._E_step(X)\n",
    "            new_mean, new_cov, new_size = self._M_step(R, X)\n",
    "            #print(i,new_mean, new_cov, new_size)\n",
    "            \n",
    "            self.u, is_close_1 = self._update(self.u, new_mean)\n",
    "            self.cov, is_close_2 = self._update(self.cov, new_cov)\n",
    "            self.size, is_close_3 = self._update(self.size, new_size)\n",
    "            \n",
    "            if all([is_close_1, is_close_2, is_close_3]):\n",
    "                break\n",
    "        return self\n",
    "    \n",
    "    def predict(self, X):\n",
    "        R = self._E_step(X)\n",
    "        return np.argmax(R, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-23T16:10:43.424116Z",
     "start_time": "2018-04-23T16:10:43.400052Z"
    }
   },
   "outputs": [],
   "source": [
    "third_X = iris_X[:, 2].reshape(-1, 1)\n",
    "model = MyGMM(u, stddev, size).fit(iris_X[:, 2].reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a. Print out the GMM parameters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-23T16:10:43.428127Z",
     "start_time": "2018-04-23T16:10:43.425119Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean   [1.46168703 4.83405382 4.8341634 ]\n",
      "stddev [0.66605551 1.19305719 1.19306461]\n",
      "size   [0.31889309 0.34055867 0.34054824]\n"
     ]
    }
   ],
   "source": [
    "print('mean  ', model.u)\n",
    "print('stddev', model.cov**0.5)\n",
    "print('size  ', model.size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b. If you want to convert the “soft” clustering results to “hard” clustering ones, how do you do it? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ANS: Using np.argmax over $r_{ic}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "def predict(self, X):\n",
    "    R = self._E_step(X)\n",
    "    return np.argmax(R, axis=1)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-23T16:10:43.435145Z",
     "start_time": "2018-04-23T16:10:43.429129Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8333333333333334"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(iris_y, model.predict(third_X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c. Use your method in (b) to find the number of members in each cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-23T16:10:43.442164Z",
     "start_time": "2018-04-23T16:10:43.436149Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([50, 75, 25], dtype=int64)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.bincount(model.predict(third_X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 . We used the play/no play  example in the lecture. You are required to  write a program to compute the C 4.5 decision tree with the “play/no play” data given in the  PPT  file.  \n",
    "\n",
    "Plot  the  computed  decision  tree. \n",
    "\n",
    "In  this  problem,  you  need  to convert  continuous  variables  of  temperature  and  humidity  to  discrete  values according to the rules given in the PPT file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-23T16:10:43.448180Z",
     "start_time": "2018-04-23T16:10:43.443167Z"
    }
   },
   "outputs": [],
   "source": [
    "feature_names = ['outlook', 'temp', 'humidity', 'windy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-23T16:10:43.454196Z",
     "start_time": "2018-04-23T16:10:43.449182Z"
    }
   },
   "outputs": [],
   "source": [
    "data_y = np.array([0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-23T16:10:43.460563Z",
     "start_time": "2018-04-23T16:10:43.454277Z"
    }
   },
   "outputs": [],
   "source": [
    "data_X = np.array([['sunny',    85, 85, 0],\n",
    "                   ['sunny',    80, 90, 1],\n",
    "                   ['overcast', 83, 78, 0],\n",
    "                   ['rain',     70, 96, 0],\n",
    "                   ['rain',     68, 80, 0],\n",
    "                   ['rain',     65, 70, 1],\n",
    "                   ['overcast', 64, 65, 1],\n",
    "                   ['sunny',    72, 95, 0],\n",
    "                   ['sunny',    69, 70, 0],\n",
    "                   ['rain',     75, 80, 0],\n",
    "                   ['sunny',    75, 70, 1],\n",
    "                   ['overcast', 72, 90, 1],\n",
    "                   ['overcast', 81, 75, 0],\n",
    "                   ['rain',     71, 80, 1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-23T16:10:43.467582Z",
     "start_time": "2018-04-23T16:10:43.461567Z"
    }
   },
   "outputs": [],
   "source": [
    "temper_mask = data_X[:, 1].astype('int')\n",
    "data_X[:, 1][temper_mask >= 80] = 'hot'\n",
    "data_X[:, 1][(temper_mask >= 70) & (temper_mask <= 79)] = 'sweet'\n",
    "data_X[:, 1][temper_mask < 70] = 'cold'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-23T16:10:43.474600Z",
     "start_time": "2018-04-23T16:10:43.468585Z"
    }
   },
   "outputs": [],
   "source": [
    "humidity_mask = data_X[:, 2].astype('int')\n",
    "data_X[:, 2][humidity_mask >= 76] = 'high'\n",
    "data_X[:, 2][humidity_mask < 76] = 'low'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-23T16:10:43.480617Z",
     "start_time": "2018-04-23T16:10:43.475603Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['sunny', 'hot', 'high', '0'],\n",
       "       ['sunny', 'hot', 'high', '1'],\n",
       "       ['overcast', 'hot', 'high', '0'],\n",
       "       ['rain', 'sweet', 'high', '0'],\n",
       "       ['rain', 'cold', 'high', '0'],\n",
       "       ['rain', 'cold', 'low', '1'],\n",
       "       ['overcast', 'cold', 'low', '1'],\n",
       "       ['sunny', 'sweet', 'high', '0'],\n",
       "       ['sunny', 'cold', 'low', '0'],\n",
       "       ['rain', 'sweet', 'high', '0'],\n",
       "       ['sunny', 'sweet', 'low', '1'],\n",
       "       ['overcast', 'sweet', 'high', '1'],\n",
       "       ['overcast', 'hot', 'low', '0'],\n",
       "       ['rain', 'sweet', 'high', '1']], dtype='<U8')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-23T16:10:43.487635Z",
     "start_time": "2018-04-23T16:10:43.481619Z"
    }
   },
   "outputs": [],
   "source": [
    "def entropy(S):\n",
    "    n = S.shape[0]\n",
    "    En = 0\n",
    "    for u, count in zip(*np.unique(S, return_counts=True)):\n",
    "        En += -1*(count/n)*np.log2(count/n)\n",
    "    return En\n",
    "#entropy(data_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-23T16:10:43.495656Z",
     "start_time": "2018-04-23T16:10:43.488638Z"
    }
   },
   "outputs": [],
   "source": [
    "def gain(S, T):\n",
    "    En = entropy(S)\n",
    "    n = S.shape[0]\n",
    "    for u, count in zip(*np.unique(T, return_counts=True)):\n",
    "        En -= (count/n)*entropy(S[T == u])\n",
    "    return En\n",
    "\n",
    "# for i, name in enumerate(feature_names):\n",
    "#     print('gain for \"%10s\": %f'%(name, gain(data_y, data_X[:, i])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-23T16:10:43.503678Z",
     "start_time": "2018-04-23T16:10:43.496659Z"
    }
   },
   "outputs": [],
   "source": [
    "def split_info(S, T):\n",
    "    spt_info = 0\n",
    "    n = S.shape[0]\n",
    "    for u, count in zip(*np.unique(T, return_counts=True)):\n",
    "        spt_info += -1*(count/n)*np.log2(count/n)\n",
    "    return spt_info\n",
    "\n",
    "# for i, name in enumerate(feature_names):\n",
    "#     print('split_info for \"%10s\": %f'%(name, split_info(data_y, data_X[:, i])))        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-23T16:10:43.510696Z",
     "start_time": "2018-04-23T16:10:43.504682Z"
    }
   },
   "outputs": [],
   "source": [
    "def gain_ratio(S, T):\n",
    "    return gain(S, T)/split_info(S, T)\n",
    "\n",
    "# for i, name in enumerate(feature_names):\n",
    "#     print('gain_ratio for \"%10s\": %f'%(name, gain_ratio(data_y, data_X[:, i]))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-23T16:10:43.517715Z",
     "start_time": "2018-04-23T16:10:43.511699Z"
    }
   },
   "outputs": [],
   "source": [
    "def best_splitting_feature(X, features, y):\n",
    "    gr = [gain_ratio(y, X[:, i]) for i, name in enumerate(features)]\n",
    "    return np.argmax(gr)\n",
    "\n",
    "#best_splitting_feature(data_X, feature_names, data_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-23T16:10:43.523731Z",
     "start_time": "2018-04-23T16:10:43.518718Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_leaf(target_values):\n",
    "    \n",
    "    leaf = {'splitting_feature' : None,\n",
    "            'sub_tree' : None,\n",
    "            'is_leaf':True }  \n",
    "    \n",
    "    num_ones = len(target_values[target_values == 1])\n",
    "    num_zero = len(target_values[target_values == 0])\n",
    "    \n",
    "    leaf['prediction'] =  int(num_ones > num_zero)                 \n",
    "               \n",
    "    return leaf "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-23T16:10:43.564840Z",
     "start_time": "2018-04-23T16:10:43.524733Z"
    }
   },
   "outputs": [],
   "source": [
    "def decision_tree_create(X, features, y, current_depth=0, max_depth=10):\n",
    "    remaining_features = features.copy()\n",
    "    \n",
    "    print (\"--------------------------------------------------------------------\")\n",
    "    print (\"Subtree, depth = %s (%s data points).\" % (current_depth, len(y)))\n",
    "    \n",
    "\n",
    "    '''\n",
    "    if all Examples are positive or negative, \n",
    "        return the single-node tree Root, with label=1 or 0\n",
    "    '''\n",
    "    if  len(np.unique(y)) == 1:  \n",
    "        print (\"Stopping condition 1 & 2 reached.\"  )   \n",
    "        return create_leaf(y)\n",
    "     \n",
    "    \n",
    "    # Additional stopping condition (limit tree depth)\n",
    "    if current_depth >= max_depth: \n",
    "        print (\"Reached maximum depth. Stopping for now.\")\n",
    "        return create_leaf(y)\n",
    "\n",
    "    # Find the best splitting feature (recall the function best_splitting_feature implemented above)\n",
    "    #print(X, features, y)\n",
    "    best_feature_idx = best_splitting_feature(X, features, y)\n",
    "    \n",
    "    # Split on the best feature that we found. \n",
    "    sub_tree_data = []\n",
    "    unigue = np.unique(X[:, best_feature_idx])\n",
    "    for u in unigue:\n",
    "        mask = X[:, best_feature_idx] == u\n",
    "        each_tree_X = np.delete(X[mask], best_feature_idx, axis=1)\n",
    "        each_tree_y = y[mask]\n",
    "        if each_tree_X.shape[0] > 0:\n",
    "            sub_tree_data.append({'X':each_tree_X, 'y':each_tree_y})\n",
    "    \n",
    "    print (\"Split on feature %s. (%s)\"\n",
    "           % (remaining_features[best_feature_idx], \n",
    "                                              len(sub_tree_data)))\n",
    "    \n",
    "    remaining_features.remove(remaining_features[best_feature_idx])\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Create a leaf node if the split is \"perfect\"\n",
    "    if len(sub_tree_data) == 1:\n",
    "        print (\"Creating leaf node.\")\n",
    "        return create_leaf(sub_tree[0]['y'])\n",
    "\n",
    "    # Repeat (recurse) on each subtrees    \n",
    "    sub_tree = {u:decision_tree_create(each_sub['X'], \n",
    "                                       remaining_features, each_sub['y'], \n",
    "                                       current_depth+1, max_depth)\n",
    "                \n",
    "                for u, each_sub in zip(unigue, sub_tree_data)}\n",
    "    \n",
    "    return {'is_leaf'          : False, \n",
    "            'prediction'       : None,\n",
    "            'splitting_feature': best_feature_idx,\n",
    "            'sub_tree' : sub_tree}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-23T16:10:43.570856Z",
     "start_time": "2018-04-23T16:10:43.565843Z"
    }
   },
   "outputs": [],
   "source": [
    "def count_nodes(tree):\n",
    "    if tree['is_leaf']:\n",
    "        return 1\n",
    "    return 1 + sum([count_nodes(sub) for _, sub in tree['sub_tree'].items()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "預設深度使用1，比照ppt example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-23T16:10:43.591551Z",
     "start_time": "2018-04-23T16:10:43.571859Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 0 (14 data points).\n",
      "Split on feature outlook. (3)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 1 (4 data points).\n",
      "Stopping condition 1 & 2 reached.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 1 (5 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 1 (5 data points).\n",
      "Reached maximum depth. Stopping for now.\n"
     ]
    }
   ],
   "source": [
    "decision_tree = decision_tree_create(data_X, feature_names, data_y, max_depth=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-23T16:10:43.607178Z",
     "start_time": "2018-04-23T16:10:43.591551Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_nodes(decision_tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting the computed decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-23T16:10:43.621477Z",
     "start_time": "2018-04-23T16:10:43.607178Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'is_leaf': False,\n",
       " 'prediction': None,\n",
       " 'splitting_feature': 0,\n",
       " 'sub_tree': {'overcast': {'is_leaf': True,\n",
       "   'prediction': 1,\n",
       "   'splitting_feature': None,\n",
       "   'sub_tree': None},\n",
       "  'rain': {'is_leaf': True,\n",
       "   'prediction': 1,\n",
       "   'splitting_feature': None,\n",
       "   'sub_tree': None},\n",
       "  'sunny': {'is_leaf': True,\n",
       "   'prediction': 0,\n",
       "   'splitting_feature': None,\n",
       "   'sub_tree': None}}}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decision_tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-23T16:10:43.630499Z",
     "start_time": "2018-04-23T16:10:43.622479Z"
    }
   },
   "outputs": [],
   "source": [
    "def classify(tree, x,annotate=False):   \n",
    "    # if the node is a leaf node.\n",
    "    if tree['is_leaf']:\n",
    "        if annotate: \n",
    "            print (\"At leaf, predicting %s\" % tree['prediction'])\n",
    "        return tree['prediction'] \n",
    "    else:\n",
    "        # split on feature.\n",
    "        split_feature = x[tree['splitting_feature']]\n",
    "        \n",
    "        if annotate: \n",
    "            print (\"Split on %s = %s\" % (tree['splitting_feature'], split_feature_value))\n",
    "        return classify(tree['sub_tree'][split_feature], x, annotate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-23T16:10:43.639524Z",
     "start_time": "2018-04-23T16:10:43.631502Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Play? ANS: True \n"
     ]
    }
   ],
   "source": [
    "print ('Play? ANS: %s ' % (bool(classify(decision_tree, ['overcast', 'sweet', 'low', '0']))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5 . Based on your C4.5 program on problem 4, revise it to accept continuous values of temperature and humidity.  \n",
    "\n",
    "Inside  your program, there must be a routine to convert each continuous number into three values, namely, low, mid, and high, based on maximizing gains. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (a) Use a pseudo code to explain how to perform the computation. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 1: list all sorted values in training set. EX: Humidity in the working problem.\n",
    "\n",
    "Step 2: remove redundancy.\n",
    "\n",
    "Step 3: Let the humidity be partitioned as {H1 <= H <= H0}, {H1 > H} and {H > H0}, where H0 H1 are number in the list in step 2.\n",
    "\n",
    "Step 4: Compute all Gains based on all possible H0 and H1.\n",
    "\n",
    "Step 5: Pick H0 and H2 with max Gain.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (b) Run  your program to print out the conversion rules (such as temperature greater than xx is hot)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-23T16:10:43.848078Z",
     "start_time": "2018-04-23T16:10:43.843065Z"
    }
   },
   "outputs": [],
   "source": [
    "data_X = np.array([['sunny',    85, 85, 0],\n",
    "                   ['sunny',    80, 90, 1],\n",
    "                   ['overcast', 83, 78, 0],\n",
    "                   ['rain',     70, 96, 0],\n",
    "                   ['rain',     68, 80, 0],\n",
    "                   ['rain',     65, 70, 1],\n",
    "                   ['overcast', 64, 65, 1],\n",
    "                   ['sunny',    72, 95, 0],\n",
    "                   ['sunny',    69, 70, 0],\n",
    "                   ['rain',     75, 80, 0],\n",
    "                   ['sunny',    75, 70, 1],\n",
    "                   ['overcast', 72, 90, 1],\n",
    "                   ['overcast', 81, 75, 0],\n",
    "                   ['rain',     71, 80, 1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-23T16:10:43.857102Z",
     "start_time": "2018-04-23T16:10:43.849081Z"
    }
   },
   "outputs": [],
   "source": [
    "temperature = data_X[:, 1].astype('int')\n",
    "humidity = data_X[:, 2].astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-23T16:10:43.864120Z",
     "start_time": "2018-04-23T16:10:43.858105Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([85, 80, 83, 70, 68, 65, 64, 72, 69, 75, 75, 72, 81, 71])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-23T16:10:43.871139Z",
     "start_time": "2018-04-23T16:10:43.865124Z"
    }
   },
   "outputs": [],
   "source": [
    "def chunk(X, H0, H1):\n",
    "    result = []\n",
    "    for i in X:\n",
    "        if i > H1:\n",
    "            result.append('high'.format(H1))\n",
    "        elif i <= H0:\n",
    "            result.append('low'.format(H0))\n",
    "        else:\n",
    "            result.append('mid'.format(H0))\n",
    "    return np.array(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-23T16:10:43.877155Z",
     "start_time": "2018-04-23T16:10:43.872142Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def discretize(X, y):\n",
    "    result = []\n",
    "    unique = np.unique(X)\n",
    "    H_pair = list(itertools.combinations(unique, 2))\n",
    "    for pair in H_pair:\n",
    "        result.append((pair, gain(y, chunk(X, pair[0], pair[1]))))\n",
    "    return max(result, key=lambda x:x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-23T16:10:43.891193Z",
     "start_time": "2018-04-23T16:10:43.878158Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((80, 83), 0.19726714791298539)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "discretize(temperature, data_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-23T16:10:43.898213Z",
     "start_time": "2018-04-23T16:10:43.892196Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((80, 95), 0.21721788321248015)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "discretize(humidity, data_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-23T16:10:43.902222Z",
     "start_time": "2018-04-23T16:10:43.899215Z"
    }
   },
   "outputs": [],
   "source": [
    "data_X[:, 1] = chunk(data_X[:, 1].astype('int') , 80, 83)\n",
    "data_X[:, 2] = chunk(data_X[:, 2].astype('int') , 80, 95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-23T16:10:43.909240Z",
     "start_time": "2018-04-23T16:10:43.903224Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['sunny', 'high', 'mid', '0'],\n",
       "       ['sunny', 'low', 'mid', '1'],\n",
       "       ['overcast', 'mid', 'low', '0'],\n",
       "       ['rain', 'low', 'high', '0'],\n",
       "       ['rain', 'low', 'low', '0'],\n",
       "       ['rain', 'low', 'low', '1'],\n",
       "       ['overcast', 'low', 'low', '1'],\n",
       "       ['sunny', 'low', 'mid', '0'],\n",
       "       ['sunny', 'low', 'low', '0'],\n",
       "       ['rain', 'low', 'low', '0'],\n",
       "       ['sunny', 'low', 'low', '1'],\n",
       "       ['overcast', 'low', 'mid', '1'],\n",
       "       ['overcast', 'mid', 'low', '0'],\n",
       "       ['rain', 'low', 'low', '1']], dtype='<U8')"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-23T16:10:43.918265Z",
     "start_time": "2018-04-23T16:10:43.910243Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 0 (14 data points).\n",
      "Split on feature temp. (3)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 1 (1 data points).\n",
      "Stopping condition 1 & 2 reached.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 1 (11 data points).\n",
      "Split on feature humidity. (3)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (1 data points).\n",
      "Stopping condition 1 & 2 reached.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (7 data points).\n",
      "Split on feature windy. (2)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 3 (3 data points).\n",
      "Stopping condition 1 & 2 reached.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 3 (4 data points).\n",
      "Split on feature outlook. (3)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 4 (1 data points).\n",
      "Stopping condition 1 & 2 reached.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 4 (2 data points).\n",
      "Stopping condition 1 & 2 reached.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 4 (1 data points).\n",
      "Stopping condition 1 & 2 reached.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (3 data points).\n",
      "Split on feature outlook. (2)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 3 (1 data points).\n",
      "Stopping condition 1 & 2 reached.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 3 (2 data points).\n",
      "Stopping condition 1 & 2 reached.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 1 (2 data points).\n",
      "Stopping condition 1 & 2 reached.\n"
     ]
    }
   ],
   "source": [
    "decision_tree = decision_tree_create(data_X, feature_names, data_y, max_depth=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-23T16:10:43.922275Z",
     "start_time": "2018-04-23T16:10:43.919267Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_nodes(decision_tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (c) draw the decision tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-23T16:10:43.939322Z",
     "start_time": "2018-04-23T16:10:43.936312Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'is_leaf': False,\n",
       " 'prediction': None,\n",
       " 'splitting_feature': 1,\n",
       " 'sub_tree': {'high': {'is_leaf': True,\n",
       "   'prediction': 0,\n",
       "   'splitting_feature': None,\n",
       "   'sub_tree': None},\n",
       "  'low': {'is_leaf': False,\n",
       "   'prediction': None,\n",
       "   'splitting_feature': 1,\n",
       "   'sub_tree': {'high': {'is_leaf': True,\n",
       "     'prediction': 1,\n",
       "     'splitting_feature': None,\n",
       "     'sub_tree': None},\n",
       "    'low': {'is_leaf': False,\n",
       "     'prediction': None,\n",
       "     'splitting_feature': 1,\n",
       "     'sub_tree': {'0': {'is_leaf': True,\n",
       "       'prediction': 1,\n",
       "       'splitting_feature': None,\n",
       "       'sub_tree': None},\n",
       "      '1': {'is_leaf': False,\n",
       "       'prediction': None,\n",
       "       'splitting_feature': 0,\n",
       "       'sub_tree': {'overcast': {'is_leaf': True,\n",
       "         'prediction': 1,\n",
       "         'splitting_feature': None,\n",
       "         'sub_tree': None},\n",
       "        'rain': {'is_leaf': True,\n",
       "         'prediction': 0,\n",
       "         'splitting_feature': None,\n",
       "         'sub_tree': None},\n",
       "        'sunny': {'is_leaf': True,\n",
       "         'prediction': 1,\n",
       "         'splitting_feature': None,\n",
       "         'sub_tree': None}}}}},\n",
       "    'mid': {'is_leaf': False,\n",
       "     'prediction': None,\n",
       "     'splitting_feature': 0,\n",
       "     'sub_tree': {'overcast': {'is_leaf': True,\n",
       "       'prediction': 1,\n",
       "       'splitting_feature': None,\n",
       "       'sub_tree': None},\n",
       "      'sunny': {'is_leaf': True,\n",
       "       'prediction': 0,\n",
       "       'splitting_feature': None,\n",
       "       'sub_tree': None}}}}},\n",
       "  'mid': {'is_leaf': True,\n",
       "   'prediction': 1,\n",
       "   'splitting_feature': None,\n",
       "   'sub_tree': None}}}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decision_tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
