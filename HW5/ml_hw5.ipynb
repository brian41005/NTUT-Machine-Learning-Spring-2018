{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 103590450 四資四 馬茂源"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-23T01:24:54.506114Z",
     "start_time": "2018-05-23T01:24:52.429775Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from scipy.stats import multivariate_normal, norm\n",
    "import numpy as np\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2 .\tCompute the complete update (back propagation) equations for all weights (𝑤1⁡~⁡𝑤8) in the following neural networks. This time, the activation function in the hidden layer is ReLU and that in the output layer remains sigmoid. In addition, use softmax as the cost function. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\[\n",
    "    f(x)= \n",
    "\\begin{cases}\n",
    "    1,& \\text{if } x >  0\\\\\n",
    "    0,& \\text{if } x \\leq 0\\\\\n",
    "\\end{cases}\n",
    "\\]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\frac{\\partial\\varepsilon}{\\partial w_{1}}$ = -d1(1-y1)w5 f(q1) x1 - d2(1-y2)w7 f(q1) x1\n",
    "\n",
    "$\\frac{\\partial\\varepsilon}{\\partial w_{2}}$ = -d1(1-y1)w5 f(q1) x2 - d2(1-y2)w7 f(q1) x2\n",
    "\n",
    "$\\frac{\\partial\\varepsilon}{\\partial w_{3}}$ = -d1(1-y1)w6 f(q2) x1 - d2(1-y2)w8 f(q2) x1\n",
    "\n",
    "$\\frac{\\partial\\varepsilon}{\\partial w_{4}}$ = -d1(1-y1)w6 f(q2) x2 - d2(1-y2)w8 f(q2) x2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\frac{\\partial\\varepsilon}{\\partial w_{5}}$ = -d1(1-y1)h1\n",
    "\n",
    "$\\frac{\\partial\\varepsilon}{\\partial w_{6}}$ = -d1(1-y1)h2\n",
    "\n",
    "$\\frac{\\partial\\varepsilon}{\\partial w_{7}}$ = -d2(1-y2)h1\n",
    "\n",
    "$\\frac{\\partial\\varepsilon}{\\partial w_{8}}$ = -d2(1-y2)h2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3 .\tWrite a program to implement the neural network with your back propagation equations in problem 2. To test your network, train it to distinguish the classes of versicolor and virginica in the Iris dataset using only the third and fourth features (i.e., petal length and petal width) as the inputs. As usual, use 70% of the data for training and the rest for testing. Repeat the experiments 10 times to find the average accuracy. During training, set the desired output as 1.0 for in class data and 0.0 for out of class data. Don’t forget to use random numbers as the initial weights. In addition, monitor the cost (loss) function with respect to the training epochs. Do you observe any difference when compared with the cost function plot using MSE? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-23T01:24:54.524163Z",
     "start_time": "2018-05-23T01:24:54.506114Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150, 4) (150,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['setosa', 'versicolor', 'virginica'], dtype='<U10')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris = load_iris()\n",
    "feature_names = iris.feature_names.copy()\n",
    "iris_X = iris.data\n",
    "iris_y = iris.target\n",
    "print(iris_X.shape, iris_y.shape)\n",
    "iris.target_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-23T01:24:54.527171Z",
     "start_time": "2018-05-23T01:24:54.525166Z"
    }
   },
   "outputs": [],
   "source": [
    "iris_X = iris_X[50:, [2, 3]]\n",
    "iris_y = iris_y[50:] - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-23T01:25:53.061351Z",
     "start_time": "2018-05-23T01:25:52.997180Z"
    }
   },
   "outputs": [],
   "source": [
    "class NN:\n",
    "    def __init__(self, n_epoch=60):\n",
    "        np.random.seed(40)\n",
    "        self.W = np.random.random((2, 2, 2))\n",
    "        self.n_epoch = n_epoch\n",
    "        self.lr = 0.09\n",
    "        self.enc = preprocessing.OneHotEncoder()\n",
    "        \n",
    "    def _sigmoid(self, x):\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "    \n",
    "    def _relu(self, x):\n",
    "        return np.maximum(x, 0)\n",
    "    \n",
    "    def _f(self, x):\n",
    "        return (x > 0).astype('int')\n",
    "    \n",
    "    def predict(self, X):\n",
    "        h = self._relu(X.dot(self.W[0, :, :]))\n",
    "        y = self._sigmoid(h.dot(self.W[1, :, :]))\n",
    "        return y, h, X.dot(self.W[0, :, :])\n",
    "    \n",
    "    def bp(self, x, y_pred, y_true, h, q, lr):\n",
    "        # error = y_pred - y_true\n",
    "           \n",
    "            \n",
    "        derivative_z_x = -y_true*(1-y_pred)\n",
    "        h = h.reshape(-1, 1)\n",
    "        \n",
    "        diff1 = h.dot(derivative_z_x.reshape(1, -1))\n",
    "        self.W[1, :, :] = self.W[1, :, :] - lr*diff1\n",
    "\n",
    "        diff2 = x.dot(self._f(q)*((derivative_z_x).dot(self.W[1, :, :].T)).reshape(1, -1))\n",
    "        self.W[0, :, :] = self.W[0, :, :] - lr*diff2\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        one_hot_y = self.enc.fit_transform(y.reshape(-1, 1)).toarray()\n",
    "        \n",
    "        for i in range(self.n_epoch):\n",
    "            for x, y in zip(X, one_hot_y):\n",
    "                y_pred, layer_output, q = self.predict(x.reshape(1, -1))\n",
    "                self.bp(x.reshape(-1, 1), y_pred, y, layer_output, q[0], self.lr)\n",
    "            \n",
    "        return self\n",
    "    \n",
    "    def score(self, X, y):\n",
    "        y_pred, _, _ = self.predict(X)\n",
    "        # print(y_pred)\n",
    "        return accuracy_score(y, np.argmax(y_pred, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-23T01:25:54.118458Z",
     "start_time": "2018-05-23T01:25:54.116453Z"
    }
   },
   "outputs": [],
   "source": [
    "def nor(X):\n",
    "    return (X - np.mean(X, axis=0)) / np.std(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-23T01:25:54.903391Z",
     "start_time": "2018-05-23T01:25:54.782338Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.96"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = NN()\n",
    "model.fit(nor(iris_X), iris_y)\n",
    "model.score(nor(iris_X), iris_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-23T01:25:57.776267Z",
     "start_time": "2018-05-23T01:25:56.969176Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9666666666666667, 0.9666666666666667, 0.9666666666666667, 0.9666666666666667, 0.9666666666666667, 0.9666666666666667, 0.9666666666666667, 0.9666666666666667, 0.9666666666666667, 0.9666666666666667]\n",
      "avg acc: 0.967\n"
     ]
    }
   ],
   "source": [
    "acc = []\n",
    "for i in range(10):\n",
    "    model = NN()\n",
    "    train_X, test_X, train_y, test_y = train_test_split(iris_X, \n",
    "                                                        iris_y, \n",
    "                                                        train_size=0.7, \n",
    "                                                        test_size = 0.3)\n",
    "    train_X, test_X,  = nor(train_X), nor(test_X)\n",
    "    model.fit(train_X, train_y)\n",
    "    acc.append(model.score(test_X, test_y))\n",
    "print(acc)\n",
    "print('avg acc: %.3f'%(np.mean(acc)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4 .\tThe following shows the LeNet-5 architecture. If we use the weight-sharing approach for the first layer, compute the number of connections and trainable weights from the input layer to the first hidden layer C1. To compute the results, you need the following parameters: kernel size = 5x5, stride = 1, and no zero-padding. \n",
    "![](2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "trainable weights: (5x5+1)x6=156\n",
    "\n",
    "connections: (5x5+1)x6x28x28=122304"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5 .\tAssuming that the following is a part of convolution neural networks. Compute the resultant values (size of 3x3) if it has two input planes, stride of one, no zero-padding, and using the ReLU activation function.\n",
    "![](3.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-23T02:10:06.678877Z",
     "start_time": "2018-05-23T02:10:06.672862Z"
    }
   },
   "outputs": [],
   "source": [
    "k = np.array([[[3, 0], [-1, -1], [2, 0]], \n",
    "               [[-2, -1], [1, 6], [-3, -1]], \n",
    "               [[-2, 0], [0, -1], [3, 0]]])\n",
    "\n",
    "p = np.array([[[6, 3], [0, 1], [-4, -4], [0, 0], [1, -1]], \n",
    "              [[4, 3], [4, 0], [0, 3], [2, 4], [1, -1]], \n",
    "              [[3, 3], [-7, 7], [1, -2], [4, -2], [2, 2]], \n",
    "              [[-2, -5], [2, -2], [1, 2], [-4, 0], [2, -2]], \n",
    "              [[5, 2], [1, 1], [2, -1], [4, 1], [-1, 2]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-23T02:29:47.876125Z",
     "start_time": "2018-05-23T02:29:47.873118Z"
    }
   },
   "outputs": [],
   "source": [
    "nf = 1  # number of filters\n",
    "rf = 3  # filter size\n",
    "s = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-23T02:36:31.077591Z",
     "start_time": "2018-05-23T02:36:31.075586Z"
    }
   },
   "outputs": [],
   "source": [
    "out = np.zeros((h_range, h_range))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-23T02:37:16.939435Z",
     "start_time": "2018-05-23T02:37:16.934421Z"
    }
   },
   "outputs": [],
   "source": [
    "for z in range(nf):\n",
    "    h_range = int((p.shape[1] - rf) / s) + 1  # (W - F + 2P) / S\n",
    "    for _h in range(h_range):\n",
    "        w_range = int((p.shape[0] - rf) / s) + 1  # (W - F + 2P) / S\n",
    "        for _w in range(w_range):\n",
    "            # print(_h, _w)\n",
    "            # print(np.sum((p[_h:_h+rf, _w:_w+rf, :]*k[:, :, :])))\n",
    "            out[_h:, _w] = np.maximum((np.sum((p[_h:_h+rf, _w:_w+rf, :]*k[:, :, :]))), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-23T02:37:17.835418Z",
     "start_time": "2018-05-23T02:37:17.832410Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0., 36., 17.],\n",
       "       [42.,  0.,  0.],\n",
       "       [ 0., 22.,  0.]])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "307px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
